key,value
output_dir,/home/tahmedge/PycharmProjects/Transformer2.8/transformers/examples/summarization/bart/bart_sum_dp
fp16,False
fp16_opt_level,O1
n_gpu,1
n_tpu_cores,0
max_grad_norm,1.0
do_train,True
do_predict,False
gradient_accumulation_steps,1
server_ip,
server_port,
seed,42
model_type,bart
model_name_or_path,bart-large
config_name,
tokenizer_name,
cache_dir,
do_lower_case,False
learning_rate,3e-05
weight_decay,0.0
adam_epsilon,1e-08
warmup_steps,0
num_train_epochs,3
train_batch_size,1
eval_batch_size,4
max_source_length,100
max_target_length,20
data_dir,../dp_data/
